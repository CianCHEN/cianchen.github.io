{"meta":{"title":"CianCHEN | with code","subtitle":"分享我所知","description":"时间纷繁,乱花迷人眼,前路漫漫,勿忘初心~","author":"CianCHEN","url":"http://192.168.36.183:6888"},"pages":[{"title":"about","date":"2018-12-23T07:20:44.000Z","updated":"2018-12-23T07:21:13.987Z","comments":true,"path":"about/index.html","permalink":"http://192.168.36.183:6888/about/index.html","excerpt":"","text":"一个测试博客的网站!"},{"title":"categories","date":"2018-12-23T07:07:35.000Z","updated":"2018-12-23T07:09:11.193Z","comments":true,"path":"categories/index.html","permalink":"http://192.168.36.183:6888/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-12-23T07:07:21.000Z","updated":"2018-12-23T07:08:34.341Z","comments":true,"path":"tags/index.html","permalink":"http://192.168.36.183:6888/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"open-falcon之安装篇","slug":"open-falcon之安装篇","date":"2018-12-24T08:31:08.000Z","updated":"2018-12-25T03:01:09.420Z","comments":true,"path":"2018/12/24/open-falcon之安装篇/","link":"","permalink":"http://192.168.36.183:6888/2018/12/24/open-falcon之安装篇/","excerpt":"小米开源监控软件 - open-falcon 安装篇 open-falcon官网地址：http://open-falcon.org/ 相关的文档地址(v2.0)：https://book.open-falcon.org/zh_0_2/intro/ 官网的架构示意图 这里尽量以我的理解来说一下这个架构图每个组件的作用(大部分来自官网)： falcon-agent是部署在每一台被监控的主机上的，主要作用是负责数据采集和数据上报，另外它还有一个proxy-gateway的接口提供给用户使用，这样用户就可以自定义一些数据，然后上报给agent，agent再上报到transfer transfer是一个无状态的集群(可单点)。transfer接收agent上报的数据，然后使用一致性哈希进行数据分片、并把分片后的数据转发给graph、judge集群(transfer还会打一份数据到opentsdb)。其消耗的资源 主要是网络和CPU transfer辐射的一个组件是graph，graph组件用于存储、归档作图数据，可以集群部署。每个graph实例会处理一个分片的数据: 接收transfer发送来的分片数据，归档、存储、生成索引；接受query对该数据分片的查询请求。graph会持久存储监控数据，频繁写入磁盘，状态数据会缓存在内存，因此graph消耗的主要资源是磁盘存储、磁盘IO和内存资源。 图中API的用途是处理终端用户请求，收到查询请求后，会去多个graph里面，查询不同metric的数据，汇总后统一返回给用户。 这里顺便说一下dashboard，是一个可视化的用户管理ui，用户可以以多个维度来搜索endpoint列表，即可以根据上报的tags来搜索关联的endpoint。 Aggregato 的作用是聚合监控数据，比如说多个机器的某个指标，提供给dashboard显示 nodata 组件的作用是检测监控数据的上报异常，比如agent.alived，异常可以返回-1，重新push到transfer，从而触发告警。 tranfer辐射的还有一个叫judge的插件，judge用于实现报警策略的触发逻辑。judge实现触发计算时，会在本地缓存 触发逻辑的中间状态和定量的监控历史数据，因此会消耗较多的内存资源和计算资源。 告警judge触发需要一些触发条件，这里需要heartbeat server的策略下发，hbs是open-falcon的配置中心，负责 适配系统的配置信息、管理agent信息等。 这样judge收到告警策略(portal ui组件配置)之后进行告警判断，符合规则的就放到redis队列中，然后视配置情况进行告警或者合并告警(links组件)，告警使用的是alarm组件，alarm需要调用sender(email, 短信api…)","text":"小米开源监控软件 - open-falcon 安装篇 open-falcon官网地址：http://open-falcon.org/ 相关的文档地址(v2.0)：https://book.open-falcon.org/zh_0_2/intro/ 官网的架构示意图 这里尽量以我的理解来说一下这个架构图每个组件的作用(大部分来自官网)： falcon-agent是部署在每一台被监控的主机上的，主要作用是负责数据采集和数据上报，另外它还有一个proxy-gateway的接口提供给用户使用，这样用户就可以自定义一些数据，然后上报给agent，agent再上报到transfer transfer是一个无状态的集群(可单点)。transfer接收agent上报的数据，然后使用一致性哈希进行数据分片、并把分片后的数据转发给graph、judge集群(transfer还会打一份数据到opentsdb)。其消耗的资源 主要是网络和CPU transfer辐射的一个组件是graph，graph组件用于存储、归档作图数据，可以集群部署。每个graph实例会处理一个分片的数据: 接收transfer发送来的分片数据，归档、存储、生成索引；接受query对该数据分片的查询请求。graph会持久存储监控数据，频繁写入磁盘，状态数据会缓存在内存，因此graph消耗的主要资源是磁盘存储、磁盘IO和内存资源。 图中API的用途是处理终端用户请求，收到查询请求后，会去多个graph里面，查询不同metric的数据，汇总后统一返回给用户。 这里顺便说一下dashboard，是一个可视化的用户管理ui，用户可以以多个维度来搜索endpoint列表，即可以根据上报的tags来搜索关联的endpoint。 Aggregato 的作用是聚合监控数据，比如说多个机器的某个指标，提供给dashboard显示 nodata 组件的作用是检测监控数据的上报异常，比如agent.alived，异常可以返回-1，重新push到transfer，从而触发告警。 tranfer辐射的还有一个叫judge的插件，judge用于实现报警策略的触发逻辑。judge实现触发计算时，会在本地缓存 触发逻辑的中间状态和定量的监控历史数据，因此会消耗较多的内存资源和计算资源。 告警judge触发需要一些触发条件，这里需要heartbeat server的策略下发，hbs是open-falcon的配置中心，负责 适配系统的配置信息、管理agent信息等。 这样judge收到告警策略(portal ui组件配置)之后进行告警判断，符合规则的就放到redis队列中，然后视配置情况进行告警或者合并告警(links组件)，告警使用的是alarm组件，alarm需要调用sender(email, 短信api…) https://book.open-falcon.org/zh_0_2/practice/deploy.html 编译安装后端这里我机器的原因我只会进行单机的安装，有条件的可以实现以下集群安装：安装环境：12345OS：CentOS Linux release 7.3.1611 (Core)go version： go1.9.4 linux/amd64git version： 1.8.3.1redis： 3.2.10mysql：5.7.18 这里我的mysql是源码安装以外，其它都使用yum安装方式。yum install git golang redis 基础环境配置之后，设置一下GOPATH环境变量123vim ~/.bashrcexport GOPATH=/opt/gosource ~/.bashrc #这个是自定义的，可以理解成你放go代码的地方，通常地下还需要有src(放源码)，pkg，bin 三个目录，而这个路径又叫做workspace #这里务必写对，除了GOPATH是你自定义的，其他请按照这个来，不然编译的时候会出错 123mkdir -p $GOPATH/src/github.com/open-falconcd $GOPATH/src/github.com/open-falcongit clone https://github.com/open-falcon/falcon-plus.git 创建需要的数据库先来看看需要导入的5个sql文件导入到mysql数据库1234cd $GOPATH/src/github.com/open-falcon/falcon-plus/scripts/mysql/db_schemafor i in \\`ls ./\\` ;​ do mysql -uroot -P4400 -h127.0.0.1 -p123456 &lt; $i;done 创建编译后的文件地址mkdir /opt/open-falcon 编译open-falcon后端服务1234cd $GOPATH/src/github.com/open-falcon/falcon-plus/make allmake agentmake pack 执行成功出现下边这个压缩包： open-falcon-v0.2.1.tar.gz 1tar -xf open-falcon-v0.2.1.tar.gz -C /opt/open-falcon/ 修改mysql的端口和密码，否则启动失败123cd /opt/open-falcongrep -Ilr 3306 ./ | xargs -n1 -- sed -i &apos;s/root:/root:123456/g&apos;grep -Ilr 3306 ./ | xargs -n1 -- sed -i &apos;s/3306/4400/g&apos; 启动后端：./open-falcon start观察一下成功输出 检查后端：./open-falcon check观察一下check输出 安装前端选择性安装依赖：12yum install -y python-virtualenv python-devel openldap-devel mysql-develyum groupinstall &quot;Development tools&quot; 安装dashboard12cd /opt/open-falcongit clone https://github.com/open-falcon/dashboard.git 创建一个虚拟python环境env12cd dashboardvirtualenv ./env 使用虚拟环境安装python依赖，独立于宿主机1./env/bin/pip install -r pip_requirements.txt -i https://pypi.douban.com/simple 修改一下rrd的配置文件，主要是mysql的配置，其他按需修改1234567vim rrd/config.pyPORTAL_DB_HOST = os.environ.get(&quot;PORTAL_DB_HOST&quot;,&quot;127.0.0.1&quot;)PORTAL_DB_PORT = int(os.environ.get(&quot;PORTAL_DB_PORT&quot;,4400))PORTAL_DB_USER = os.environ.get(&quot;PORTAL_DB_USER&quot;,&quot;root&quot;)PORTAL_DB_PASS = os.environ.get(&quot;PORTAL_DB_PASS&quot;,&quot;123456&quot;)API_ADDR = os.environ.get(&quot;API_ADDR&quot;,&quot;http://192.168.36.183:8080/api/v1&quot;) //这个修改成外网的ip 启动前端：./env/bin/python wsgi.py #这是以开发者模式启动，将会阻塞终端或者./control start #以生产环境启动，另外./control stop就是停止dashboard 查看日志./control tail #查看日志 其他各相关的日志在各自模块下的log文件夹下 使用的相关端口[root@int-test-1 dashboard]# netstat -tunpl | grep fa tcp6 0 0 :::6055 :::* LISTEN 7166/falcon-aggrega tcp6 0 0 :::6090 :::* LISTEN 7158/falcon-nodata tcp6 0 0 :::6060 :::* LISTEN 7552/falcon-transfe tcp6 0 0 :::14444 :::* LISTEN 7186/falcon-gateway tcp6 0 0 :::6030 :::* LISTEN 7136/falcon-hbs tcp6 0 0 :::6031 :::* LISTEN 7136/falcon-hbs tcp6 0 0 :::8080 :::* LISTEN 7195/falcon-api tcp6 0 0 :::8433 :::* LISTEN 7552/falcon-transfe tcp6 0 0 :::6070 :::* LISTEN 7122/falcon-graph tcp6 0 0 :::6071 :::* LISTEN 7122/falcon-graph tcp6 0 0 :::9912 :::* LISTEN 7209/falcon-alarm tcp6 0 0 :::3000 :::* LISTEN 994/grafana-server tcp6 0 0 :::4444 :::* LISTEN 7552/falcon-transfe tcp6 0 0 :::16060 :::* LISTEN 7186/falcon-gateway tcp6 0 0 :::6080 :::* LISTEN 7147/falcon-judge tcp6 0 0 :::18433 :::* LISTEN 7186/falcon-gateway tcp6 0 0 :::6081 :::* LISTEN 7147/falcon-judge tcp6 0 0 :::1988 :::* LISTEN 7176/falcon-agent tcp 0 0 0.0.0.0:8081 0.0.0.0:* LISTEN 10660/python 8081端口是dashboard的端口，访问前端：http://192.168.36.183:8081/ 使用dashboard登录之后需要先注册一个账号 填写相关的信息，注意邮箱地址，告警的时候会使用到 登录之后可以修改用户信息 查看dashboard 查看/过滤 endpoint 和counter 查看监控图像 好了，到这里就可以简单的查看监控的counter和监控图像了，接下来一篇会部署agent到其他节点，部署告警策略。","categories":[{"name":"open-falcon","slug":"open-falcon","permalink":"http://192.168.36.183:6888/categories/open-falcon/"}],"tags":[{"name":"open-falcon","slug":"open-falcon","permalink":"http://192.168.36.183:6888/tags/open-falcon/"}]},{"title":"Zabbix LLD Discovery - zabbix监控之低等级发现","slug":"Zabbix-LLD-Discovery-zabbix监控之低等级发现","date":"2018-12-21T07:12:03.000Z","updated":"2018-12-24T03:32:43.050Z","comments":true,"path":"2018/12/21/Zabbix-LLD-Discovery-zabbix监控之低等级发现/","link":"","permalink":"http://192.168.36.183:6888/2018/12/21/Zabbix-LLD-Discovery-zabbix监控之低等级发现/","excerpt":"zabbix 的Regular expressions以下是一个zabbix文件系统自动发现的正则表达式，匹配到的话返回true：下面看一下文件系统自动发现的具体配置：在zabbix server通过zabbix_get获取一下文件系统发现的全部key：","text":"zabbix 的Regular expressions以下是一个zabbix文件系统自动发现的正则表达式，匹配到的话返回true：下面看一下文件系统自动发现的具体配置：在zabbix server通过zabbix_get获取一下文件系统发现的全部key：可以观察到，这里匹配{ #FSTYPE }的这个key，必须要符合上述正则表达式(返回True)才会返回，这个是zabbix自带的自动发现。再说说这个Filters的作用：实际上就是一个限制作用，只有符合我们自定义的规则，才会返回到zabbix的监控项，否则就不返回，这个看个人具体需求，适合一些已知的监控项，比如文件系统，网卡类型等。如果是不可控的可变类型，建议不要使用，会导致匹配失败而不能发现监控项。 监控实例单监控key实例1 监控mysql是否在线新建监控模板通常我的做法是新加一个lld规则，新建一个模板，填上模板名称即可 新建应用(aapplication)我这里把下一个实例的应用也同时创建了 添加监控脚本这一步是重点，通过自定义的脚本来为zabbix添加自定义key脚本输出必须为标准的json格式，至于用py 还是 shell自己选择，我是觉得系统数据获取还是shell比较方便修改zabbix_agentd.conf重启zabbix_agentd 就可以获取对应添加的key了，下面测试一下mysql.alived 就是添加的自定义key，可以正常返回获取对应{ #MYSQL_PORT } 端口的值：zabbix_get -s 192.168.236.32 -k &quot;mysql.alive[5500]&quot;以上测试通过之后可以进行下一步，这里注意脚本的权限，zabbix用户务必具有执行权限。 配置zabbix自动发现在zabbix面板新建两个discovery rules 配置discovery rule，这里Filters暂时不使用 为模板添加items 配置items 创建报警触发器 配置触发器我这里是正常返会1，异常返回0。当最后一次的值小于1时触发告警，告警级别为Disaster。 创建监控图表 配置监控图表以上就完成一个lld 自动发现模板的配置了。 监控测试进入到套用此模板的服务器，查看自动发现item是否已经正常加入监控。我们过滤一下mysql_alived这个application，可以看到监控项正常加入 测试告警可以关闭监控mysql进行。实例2 监控mysql主从(一从多主)关系是否正常参照2.1的配置就行了，就是修改一下key的名称即可。多监控key实例1 监控mysql主从(一从多主)延时监控脚本返回这个的步骤其实跟上边也是差不多的，先来看看监控返回格式这里其实就跟一开始我们分析的文件系统自动返现那里是类似的。跟上例子不一样的是，这里使用了两个json key作为一个分组，分别是{ #MYSQL_PORT } { #CHANNEL_NAME },我们现在要实现的是监控这些端口下所有channel的mysql主从同步的 Second_behind_master参数，所以我们必须先得到所有的mysql port 和 每个port 下对应的channel名称才能得到Second_behind_master的值。 这里mysql.behind 也是自定义的监控key，在zabbix_agentd.conf进行自定义添加即可。 配置regular expression新建一个regular expression，这里用途是匹配一从多主的channel_name,等下会用到 配置zabbix 自动发现新建一个模板，新建application，新建discovery rule这里filters使用上边刚刚添加的regular expression新建items这里{ #MYSQL_PORT } 和 { #CHANNEL_NAME } 的使用其实就很明确了，你得事先让zabbix知道他们分别代指什么东西，之后zabbix就能将他们作为数据参数来使用了，这就是为什么一开始就要先获取到这两个key的全部数据。 接下来添加触发器和添加图标的操作是一样的：下面是图表添加的范例 监控测试进入到套用模板的机器，过滤对应的application","categories":[{"name":"Zabbix 监控","slug":"Zabbix-监控","permalink":"http://192.168.36.183:6888/categories/Zabbix-监控/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://192.168.36.183:6888/tags/hexo/"},{"name":"zabbix","slug":"zabbix","permalink":"http://192.168.36.183:6888/tags/zabbix/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-12-21T05:47:07.153Z","updated":"2018-12-21T05:47:07.153Z","comments":true,"path":"2018/12/21/hello-world/","link":"","permalink":"http://192.168.36.183:6888/2018/12/21/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}