{"meta":{"title":"CianCHEN | with code","subtitle":"分享我所知","description":"世间纷繁,乱花迷人眼,前路漫漫,勿忘初心~","author":"CianCHEN","url":"http://192.168.36.183:6888"},"pages":[{"title":"about","date":"2018-12-23T07:20:44.000Z","updated":"2018-12-23T07:21:13.987Z","comments":true,"path":"about/index.html","permalink":"http://192.168.36.183:6888/about/index.html","excerpt":"","text":"一个测试博客的网站!"},{"title":"categories","date":"2018-12-23T07:07:35.000Z","updated":"2018-12-23T07:09:11.193Z","comments":true,"path":"categories/index.html","permalink":"http://192.168.36.183:6888/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-12-23T07:07:21.000Z","updated":"2018-12-23T07:08:34.341Z","comments":true,"path":"tags/index.html","permalink":"http://192.168.36.183:6888/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"open-falcon之告警篇","slug":"open-falcon之告警篇","date":"2018-12-25T06:38:04.000Z","updated":"2018-12-26T05:36:58.756Z","comments":true,"path":"2018/12/25/open-falcon之告警篇/","link":"","permalink":"http://192.168.36.183:6888/2018/12/25/open-falcon之告警篇/","excerpt":"在上一篇博文中，已经演示了怎样部署一套基础的监控服务端，下面要开始安装agent收集指标信息以及配置告警，实现监控基础环境信息：12server端: 192.168.36.183agent: 192.168.36.17 编译安装agent编译agent客户端agent，我们只需要编译一次即可，以后所有的agent都可以直接使用这个包了。在server端机器进行客户端编译：1234cd /opt/go/src/github.com/open-falcon/falcon-plus/modules/agent #这个目录之前在编译server的时候使用过go get ./... #需要主机可以连接外网，通过go get下载相关源码包。./control build./control pack #编译pack 出的包，在其他agent主机上部署时，无需连接外网 ，pack出的包，可以类似的理解为由c源代码编译后得出的二进制文件。 观察一下我们需要的压缩包falcon-agent-5.1.2.tar.gz 部署agent","text":"在上一篇博文中，已经演示了怎样部署一套基础的监控服务端，下面要开始安装agent收集指标信息以及配置告警，实现监控基础环境信息：12server端: 192.168.36.183agent: 192.168.36.17 编译安装agent编译agent客户端agent，我们只需要编译一次即可，以后所有的agent都可以直接使用这个包了。在server端机器进行客户端编译：1234cd /opt/go/src/github.com/open-falcon/falcon-plus/modules/agent #这个目录之前在编译server的时候使用过go get ./... #需要主机可以连接外网，通过go get下载相关源码包。./control build./control pack #编译pack 出的包，在其他agent主机上部署时，无需连接外网 ，pack出的包，可以类似的理解为由c源代码编译后得出的二进制文件。 观察一下我们需要的压缩包falcon-agent-5.1.2.tar.gz 部署agent 将包发送到客户机器上，解压123mkdir -p /usr/local/open-falcon/agentcd /usr/local/open-falcon/agenttar -xf falcon-agent-5.1.2.tar.gz -C ./ 修改相关的配置1234567891011cp cfg.example.json cfg.jsonip --&gt; agent会自动探测本机iphostname --&gt; 默认通过`hostname`获取,如果你自定义了就会覆盖，这个在dashboard显示的就是endpoint heartbeat[addr] --&gt; 192.168.36.183ignore --&gt; 选择你要忽略的监控项# 这里基本选择默认就行，按需修改，这里注意一下1988端口，这个是会暴露agent机器的所有指标信息，建议改成localhost&quot;http&quot;: &#123; &quot;enabled&quot;: true, &quot;listen&quot;: &quot;127.0.0.1:1988&quot;, &quot;backdoor&quot;: false &#125;, 开启falcon-agent./falcon-agent start检查falcon-agent是否正常./falcon-agent -check 通过访问http://192.168.36.17:1988/ 可以看到agent本机的所有详细信息，一般这个不建议监听可访问地址，上边讲过。 接着登录dashbord就可以看见新加的agentd了相关的监控信息也会出来，按需查看即可 配置告警：编译安装mail-provider这里务必注意了，告警需要alarm插件的调用，而alarm需要redis，所以必须启动redis，否则报警不成功如果之前启动server的时候没有启动redis，那么启动redis之后要记得重启一下server，否则一大堆问题。 open-falcon实现邮件报警$GOPATH –&gt; /opt/go 在服务端机器执行以下的步骤，告警是放在server端的以下操作在server端执行 编译mail-provider123456789cd $GOPATH/srccd github.com/open-falcon/# 下载mail-provider源码git clone https://github.com/open-falcon/mail-provider.gitcd mail-provider/# 安装go依赖go get ./..../control build./control pack 安装mail-provider1234567891011121314151617181920mkdir /opt/open-falcon/mail-providertar zxf falcon-mail-provider-0.0.1.tar.gz -C /opt/open-falcon/mail-provider/cd /opt/open-falcon/mail-provider/vim cfg.json #修改一下配置文件，邮件相关的信息&#123; &quot;debug&quot;: true, &quot;http&quot;: &#123; &quot;listen&quot;: &quot;0.0.0.0:4000&quot;, &quot;token&quot;: &quot;&quot; &#125;, &quot;smtp&quot;: &#123; &quot;addr&quot;: &quot;smtp.163.com:25&quot;, &quot;username&quot;: &quot;yourname@163.com&quot;, &quot;password&quot;: &quot;password@123&quot;, &quot;from&quot;: &quot;yourname163.com&quot; &#125;&#125;# 开启mail-provider./control start 测试邮件发送：1curl http://127.0.0.1:4000/sender/mail -d &quot;tos=1653581786@qq.com&amp;subject=报警测试&amp;content=这是一封测试邮件&quot; 发送邮件测试一下 –&gt; 返回success成功 需要实现告警还需要一个sender组件:上边的邮件发送插件可以用你们自己开发的接口或者三方工具都行，sender使用post方式触发 编译安装sender编译sender:12345678https://github.com/open-falcon-archive/sendercd $GOPATH/srccd github.com/open-falcon/git clone https://github.com/open-falcon/sender.gitcd sender/go get ./..../control build./control pack 安装sender123mkdir /opt/open-falcon/sendertar zxf falcon-sender-0.0.0.tar.gz -C /opt/open-falcon/sender/cd /opt/open-falcon/sender/ 修改一下配置文件：12vim cfg.json 就是将mail那里修改成http://127.0.0.1:4000/sender/mail 启动sender1./control start 到这里基础的环境就准备的差不多了，接下来去添加一下监控和告警条件 配置监控和告警需要注意，open-falcon接受告警不是单个用户的，需要定义一个告警接收组，这里区别于zabbix 用户/组管理 创建告警组 创建HostGrouphostgroup 的作用很简单，就是我需要跑的程序都是在某些机器上，那我直接把这些机器都加入到同一个hostgroup即可，不用每台机器都添加一个模板了 创建策略模板这里all(#1)==0 为告警触发条件，意思是最后一次返回的值等于0就告警具体的参考:http://book.open-falcon.org/zh_0_2/distributed_install/judge.html 绑定策略模板到HostGroup 这样简单的监控就算是可以实现了 保证server端redis正常的话，关闭一下agentd的6379端口，监听一下日志1tailf var/app.log #可以查看下日志可以看到提示邮件已经发出去了 报警间隔自己修改了，默认5min12vim /usr/local/open-falcon/judge/config/cfg.json #配置文件中配置了连续两个报警之间至少相隔的秒数&quot;minInterval&quot;: 300, 告警信息此时在alarm-dashbord也应该出现告警信息。 配置nodatahttps://github.com/open-falcon-archive/nodata这个东西就是监控项在没有数据返回的时候，返回一个自定义的值，比如agentd挂了，就没办法上报数据了，这时候nodata就发挥作用了，我自定义一个-1，告诉运维，有agentd挂了。 新建nodata 到dashboard上查看相应的counter 查看一下对应的出图 可以观察到，这个新建的counter由nodata创建是成功的，但是返回的值确实一直是异常的返回，也就是我们自定义的-1 监控原生的那个agent.alive，他是没有标签的，所以nodata那里配置不应该打上tag.当我们按照官方教程上那么设置tag之后，nodata就会去监控agent.alive/module=nodata,pdl=falcon这一项，这一Counter本来就没有数据，是nodata自己创建的。所以nodata每次都去获取agent.alive/module=nodata,pdl=falcon这项数据，发现为空，返回-1，所以这一项肯定是永远为-1的。 修改nodata接下来到nodata上去掉一开始打的tags nodata实现告警跟上边告警一样，我新建一个告警模板然后将模板绑定到hostgroup上 测试nodata告警我关闭36.17上的agent进程./control stop dashboard上agent.avlie counter观察一下出图注意这里是agent.avlie而不再是agent.alive/module=nodata,pdl=falcon了，这个带tags的counter已经不会采集数据，你可以在界面删除它可以看到，agent的值从1到-1，异常，将会触发告警，我这里会有邮件触发。 告警alarm-dashbord到这里实现了简单的告警,以及策略的编写和配置了nodata,sender。下一篇将会是简单应用监控。","categories":[{"name":"open-falcon","slug":"open-falcon","permalink":"http://192.168.36.183:6888/categories/open-falcon/"}],"tags":[{"name":"open-falcon","slug":"open-falcon","permalink":"http://192.168.36.183:6888/tags/open-falcon/"}]},{"title":"open-falcon之安装篇","slug":"open-falcon之安装篇","date":"2018-12-24T08:31:08.000Z","updated":"2018-12-25T06:18:46.586Z","comments":true,"path":"2018/12/24/open-falcon之安装篇/","link":"","permalink":"http://192.168.36.183:6888/2018/12/24/open-falcon之安装篇/","excerpt":"小米开源监控软件 - open-falcon 安装篇 open-falcon官网地址：http://open-falcon.org/ 相关的文档地址(v2.0)：https://book.open-falcon.org/zh_0_2/intro/ 官网的架构示意图 这里尽量以我的理解来说一下这个架构图每个组件的作用(大部分来自官网)： falcon-agent是部署在每一台被监控的主机上的，主要作用是负责数据采集和数据上报，另外它还有一个proxy-gateway的接口提供给用户使用，这样用户就可以自定义一些数据，然后上报给agent，agent再上报到transfer transfer是一个无状态的集群(可单点)。transfer接收agent上报的数据，然后使用一致性哈希进行数据分片、并把分片后的数据转发给graph、judge集群(transfer还会打一份数据到opentsdb)。其消耗的资源 主要是网络和CPU transfer辐射的一个组件是graph，graph组件用于存储、归档作图数据，可以集群部署。每个graph实例会处理一个分片的数据: 接收transfer发送来的分片数据，归档、存储、生成索引；接受query对该数据分片的查询请求。graph会持久存储监控数据，频繁写入磁盘，状态数据会缓存在内存，因此graph消耗的主要资源是磁盘存储、磁盘IO和内存资源。 图中API的用途是处理终端用户请求，收到查询请求后，会去多个graph里面，查询不同metric的数据，汇总后统一返回给用户。 这里顺便说一下dashboard，是一个可视化的用户管理ui，用户可以以多个维度来搜索endpoint列表，即可以根据上报的tags来搜索关联的endpoint。 Aggregato 的作用是聚合监控数据，比如说多个机器的某个指标，提供给dashboard显示 nodata 组件的作用是检测监控数据的上报异常，比如agent.alived，异常可以返回-1，重新push到transfer，从而触发告警。 tranfer辐射的还有一个叫judge的插件，judge用于实现报警策略的触发逻辑。judge实现触发计算时，会在本地缓存 触发逻辑的中间状态和定量的监控历史数据，因此会消耗较多的内存资源和计算资源。 告警judge触发需要一些触发条件，这里需要heartbeat server的策略下发，hbs是open-falcon的配置中心，负责 适配系统的配置信息、管理agent信息等。 这样judge收到告警策略(portal ui组件配置)之后进行告警判断，符合规则的就放到redis队列中，然后视配置情况进行告警或者合并告警(links组件)，告警使用的是alarm组件，alarm需要调用sender(email, 短信api…)","text":"小米开源监控软件 - open-falcon 安装篇 open-falcon官网地址：http://open-falcon.org/ 相关的文档地址(v2.0)：https://book.open-falcon.org/zh_0_2/intro/ 官网的架构示意图 这里尽量以我的理解来说一下这个架构图每个组件的作用(大部分来自官网)： falcon-agent是部署在每一台被监控的主机上的，主要作用是负责数据采集和数据上报，另外它还有一个proxy-gateway的接口提供给用户使用，这样用户就可以自定义一些数据，然后上报给agent，agent再上报到transfer transfer是一个无状态的集群(可单点)。transfer接收agent上报的数据，然后使用一致性哈希进行数据分片、并把分片后的数据转发给graph、judge集群(transfer还会打一份数据到opentsdb)。其消耗的资源 主要是网络和CPU transfer辐射的一个组件是graph，graph组件用于存储、归档作图数据，可以集群部署。每个graph实例会处理一个分片的数据: 接收transfer发送来的分片数据，归档、存储、生成索引；接受query对该数据分片的查询请求。graph会持久存储监控数据，频繁写入磁盘，状态数据会缓存在内存，因此graph消耗的主要资源是磁盘存储、磁盘IO和内存资源。 图中API的用途是处理终端用户请求，收到查询请求后，会去多个graph里面，查询不同metric的数据，汇总后统一返回给用户。 这里顺便说一下dashboard，是一个可视化的用户管理ui，用户可以以多个维度来搜索endpoint列表，即可以根据上报的tags来搜索关联的endpoint。 Aggregato 的作用是聚合监控数据，比如说多个机器的某个指标，提供给dashboard显示 nodata 组件的作用是检测监控数据的上报异常，比如agent.alived，异常可以返回-1，重新push到transfer，从而触发告警。 tranfer辐射的还有一个叫judge的插件，judge用于实现报警策略的触发逻辑。judge实现触发计算时，会在本地缓存 触发逻辑的中间状态和定量的监控历史数据，因此会消耗较多的内存资源和计算资源。 告警judge触发需要一些触发条件，这里需要heartbeat server的策略下发，hbs是open-falcon的配置中心，负责 适配系统的配置信息、管理agent信息等。 这样judge收到告警策略(portal ui组件配置)之后进行告警判断，符合规则的就放到redis队列中，然后视配置情况进行告警或者合并告警(links组件)，告警使用的是alarm组件，alarm需要调用sender(email, 短信api…) https://book.open-falcon.org/zh_0_2/practice/deploy.html 编译安装后端这里我机器的原因我只会进行单机的安装，有条件的可以实现以下集群安装：安装环境：12345OS：CentOS Linux release 7.3.1611 (Core)go version： go1.9.4 linux/amd64git version： 1.8.3.1redis： 3.2.10mysql：5.7.18 这里我的mysql是源码安装以外，其它都使用yum安装方式。yum install git golang redis 基础环境配置之后，设置一下GOPATH环境变量123vim ~/.bashrcexport GOPATH=/opt/gosource ~/.bashrc #这个是自定义的，可以理解成你放go代码的地方，通常地下还需要有src(放源码)，pkg，bin 三个目录，而这个路径又叫做workspace #这里务必写对，除了GOPATH是你自定义的，其他请按照这个来，不然编译的时候会出错 123mkdir -p $GOPATH/src/github.com/open-falconcd $GOPATH/src/github.com/open-falcongit clone https://github.com/open-falcon/falcon-plus.git 创建需要的数据库先来看看需要导入的5个sql文件导入到mysql数据库1234cd $GOPATH/src/github.com/open-falcon/falcon-plus/scripts/mysql/db_schemafor i in \\`ls ./\\` ;​ do mysql -uroot -P4400 -h127.0.0.1 -p123456 &lt; $i;done 创建编译后的文件地址mkdir /opt/open-falcon 编译open-falcon后端服务1234cd $GOPATH/src/github.com/open-falcon/falcon-plus/make allmake agentmake pack 执行成功出现下边这个压缩包： open-falcon-v0.2.1.tar.gz 1tar -xf open-falcon-v0.2.1.tar.gz -C /opt/open-falcon/ 修改mysql的端口和密码，否则启动失败123cd /opt/open-falcongrep -Ilr 3306 ./ | xargs -n1 -- sed -i &apos;s/root:/root:123456/g&apos;grep -Ilr 3306 ./ | xargs -n1 -- sed -i &apos;s/3306/4400/g&apos; 启动后端：./open-falcon start观察一下成功输出 检查后端：./open-falcon check观察一下check输出 安装前端选择性安装依赖：12yum install -y python-virtualenv python-devel openldap-devel mysql-develyum groupinstall &quot;Development tools&quot; 安装dashboard12cd /opt/open-falcongit clone https://github.com/open-falcon/dashboard.git 创建一个虚拟python环境env12cd dashboardvirtualenv ./env 使用虚拟环境安装python依赖，独立于宿主机1./env/bin/pip install -r pip_requirements.txt -i https://pypi.douban.com/simple 修改一下rrd的配置文件，主要是mysql的配置，其他按需修改1234567vim rrd/config.pyPORTAL_DB_HOST = os.environ.get(&quot;PORTAL_DB_HOST&quot;,&quot;127.0.0.1&quot;)PORTAL_DB_PORT = int(os.environ.get(&quot;PORTAL_DB_PORT&quot;,4400))PORTAL_DB_USER = os.environ.get(&quot;PORTAL_DB_USER&quot;,&quot;root&quot;)PORTAL_DB_PASS = os.environ.get(&quot;PORTAL_DB_PASS&quot;,&quot;123456&quot;)API_ADDR = os.environ.get(&quot;API_ADDR&quot;,&quot;http://192.168.36.183:8080/api/v1&quot;) //这个修改成外网的ip 启动前端：./env/bin/python wsgi.py #这是以开发者模式启动，将会阻塞终端或者./control start #以生产环境启动，另外./control stop就是停止dashboard 查看日志./control tail #查看日志 其他各相关的日志在各自模块下的log文件夹下 使用的相关端口[root@int-test-1 dashboard]# netstat -tunpl | grep fa tcp6 0 0 :::6055 :::* LISTEN 7166/falcon-aggrega tcp6 0 0 :::6090 :::* LISTEN 7158/falcon-nodata tcp6 0 0 :::6060 :::* LISTEN 7552/falcon-transfe tcp6 0 0 :::14444 :::* LISTEN 7186/falcon-gateway tcp6 0 0 :::6030 :::* LISTEN 7136/falcon-hbs tcp6 0 0 :::6031 :::* LISTEN 7136/falcon-hbs tcp6 0 0 :::8080 :::* LISTEN 7195/falcon-api tcp6 0 0 :::8433 :::* LISTEN 7552/falcon-transfe tcp6 0 0 :::6070 :::* LISTEN 7122/falcon-graph tcp6 0 0 :::6071 :::* LISTEN 7122/falcon-graph tcp6 0 0 :::9912 :::* LISTEN 7209/falcon-alarm tcp6 0 0 :::3000 :::* LISTEN 994/grafana-server tcp6 0 0 :::4444 :::* LISTEN 7552/falcon-transfe tcp6 0 0 :::16060 :::* LISTEN 7186/falcon-gateway tcp6 0 0 :::6080 :::* LISTEN 7147/falcon-judge tcp6 0 0 :::18433 :::* LISTEN 7186/falcon-gateway tcp6 0 0 :::6081 :::* LISTEN 7147/falcon-judge tcp6 0 0 :::1988 :::* LISTEN 7176/falcon-agent tcp 0 0 0.0.0.0:8081 0.0.0.0:* LISTEN 10660/python 8081端口是dashboard的端口，访问前端：http://192.168.36.183:8081/ 使用dashboard登录之后需要先注册一个账号 填写相关的信息，注意邮箱地址，告警的时候会使用到 登录之后可以修改用户信息 查看dashboard 查看/过滤 endpoint 和counter 查看监控图像 好了，到这里就可以简单的查看监控的counter和监控图像了，接下来一篇会部署agent到其他节点，部署告警策略。","categories":[{"name":"open-falcon","slug":"open-falcon","permalink":"http://192.168.36.183:6888/categories/open-falcon/"}],"tags":[{"name":"open-falcon","slug":"open-falcon","permalink":"http://192.168.36.183:6888/tags/open-falcon/"}]},{"title":"Zabbix LLD Discovery - zabbix监控之低等级发现","slug":"Zabbix-LLD-Discovery-zabbix监控之低等级发现","date":"2018-12-21T07:12:03.000Z","updated":"2018-12-24T03:32:43.050Z","comments":true,"path":"2018/12/21/Zabbix-LLD-Discovery-zabbix监控之低等级发现/","link":"","permalink":"http://192.168.36.183:6888/2018/12/21/Zabbix-LLD-Discovery-zabbix监控之低等级发现/","excerpt":"zabbix 的Regular expressions以下是一个zabbix文件系统自动发现的正则表达式，匹配到的话返回true：下面看一下文件系统自动发现的具体配置：在zabbix server通过zabbix_get获取一下文件系统发现的全部key：","text":"zabbix 的Regular expressions以下是一个zabbix文件系统自动发现的正则表达式，匹配到的话返回true：下面看一下文件系统自动发现的具体配置：在zabbix server通过zabbix_get获取一下文件系统发现的全部key：可以观察到，这里匹配{ #FSTYPE }的这个key，必须要符合上述正则表达式(返回True)才会返回，这个是zabbix自带的自动发现。再说说这个Filters的作用：实际上就是一个限制作用，只有符合我们自定义的规则，才会返回到zabbix的监控项，否则就不返回，这个看个人具体需求，适合一些已知的监控项，比如文件系统，网卡类型等。如果是不可控的可变类型，建议不要使用，会导致匹配失败而不能发现监控项。 监控实例单监控key实例1 监控mysql是否在线新建监控模板通常我的做法是新加一个lld规则，新建一个模板，填上模板名称即可 新建应用(aapplication)我这里把下一个实例的应用也同时创建了 添加监控脚本这一步是重点，通过自定义的脚本来为zabbix添加自定义key脚本输出必须为标准的json格式，至于用py 还是 shell自己选择，我是觉得系统数据获取还是shell比较方便修改zabbix_agentd.conf重启zabbix_agentd 就可以获取对应添加的key了，下面测试一下mysql.alived 就是添加的自定义key，可以正常返回获取对应{ #MYSQL_PORT } 端口的值：zabbix_get -s 192.168.236.32 -k &quot;mysql.alive[5500]&quot;以上测试通过之后可以进行下一步，这里注意脚本的权限，zabbix用户务必具有执行权限。 配置zabbix自动发现在zabbix面板新建两个discovery rules 配置discovery rule，这里Filters暂时不使用 为模板添加items 配置items 创建报警触发器 配置触发器我这里是正常返会1，异常返回0。当最后一次的值小于1时触发告警，告警级别为Disaster。 创建监控图表 配置监控图表以上就完成一个lld 自动发现模板的配置了。 监控测试进入到套用此模板的服务器，查看自动发现item是否已经正常加入监控。我们过滤一下mysql_alived这个application，可以看到监控项正常加入 测试告警可以关闭监控mysql进行。实例2 监控mysql主从(一从多主)关系是否正常参照2.1的配置就行了，就是修改一下key的名称即可。多监控key实例1 监控mysql主从(一从多主)延时监控脚本返回这个的步骤其实跟上边也是差不多的，先来看看监控返回格式这里其实就跟一开始我们分析的文件系统自动返现那里是类似的。跟上例子不一样的是，这里使用了两个json key作为一个分组，分别是{ #MYSQL_PORT } { #CHANNEL_NAME },我们现在要实现的是监控这些端口下所有channel的mysql主从同步的 Second_behind_master参数，所以我们必须先得到所有的mysql port 和 每个port 下对应的channel名称才能得到Second_behind_master的值。 这里mysql.behind 也是自定义的监控key，在zabbix_agentd.conf进行自定义添加即可。 配置regular expression新建一个regular expression，这里用途是匹配一从多主的channel_name,等下会用到 配置zabbix 自动发现新建一个模板，新建application，新建discovery rule这里filters使用上边刚刚添加的regular expression新建items这里{ #MYSQL_PORT } 和 { #CHANNEL_NAME } 的使用其实就很明确了，你得事先让zabbix知道他们分别代指什么东西，之后zabbix就能将他们作为数据参数来使用了，这就是为什么一开始就要先获取到这两个key的全部数据。 接下来添加触发器和添加图标的操作是一样的：下面是图表添加的范例 监控测试进入到套用模板的机器，过滤对应的application","categories":[{"name":"Zabbix 监控","slug":"Zabbix-监控","permalink":"http://192.168.36.183:6888/categories/Zabbix-监控/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://192.168.36.183:6888/tags/hexo/"},{"name":"zabbix","slug":"zabbix","permalink":"http://192.168.36.183:6888/tags/zabbix/"}]}]}